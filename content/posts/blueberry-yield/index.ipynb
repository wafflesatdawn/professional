{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Blueberry Yield\n",
        "date: '2023-05-08T10:05:27-07:00'\n",
        "format: hugo-md\n",
        "draft: true\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Intro about predicting blueberry harvest.\n",
        "\n",
        "Set up data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "from fastai.tabular.all import *\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
        "import dtreeviz\n",
        "from IPython.display import Image, display_svg, SVG\n",
        "\n",
        "data_path = Path('./data')\n",
        "df = pd.read_csv(data_path/'train.csv', low_memory=False)\n",
        "df_test = pd.read_csv(data_path/'test.csv', low_memory=False)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.columns\n",
        "df_test.columns\n",
        "[{df[i].name:df[i].unique()} for i in df.columns]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on how few unique values they contain, the first five columns might warrant treatment as categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.clonesize = df.clonesize.astype('category')\n",
        "df.honeybee = df.honeybee.astype('category')\n",
        "df.bumbles = df.bumbles.astype('category')\n",
        "df.andrena = df.andrena.astype('category')\n",
        "df.osmia = df.osmia.astype('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The dependent variable we are predicting is yield, and procs are wrappers on Pandas that handle strings and missing data. This dataset does not contain strings bu the functionality are grouped together. `Categorify` is a `TabularProc` that replaces a column with a numeric categorical column. `FillMissing` is a `TabularProc` that replaces missing values with the median of the column, and creates a new Boolean column that is set to `True` for any row where the value was missing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dep_var = 'yield'\n",
        "procs = [Categorify, FillMissing]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on the structure of the dataset, we will randomly split the data into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df_test\n",
        "df\n",
        "rng = np.random.default_rng()\n",
        "np.random.seed(11)\n",
        "train_size = round(len(df) * .7)\n",
        "train_idx = rng.integers(low=0, high=df.last_valid_index(), size=train_size)\n",
        "splits = (list(train_idx), list(df.index[~train_idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tell TabularPandas which columns are continuous and categorical. Save the processed data for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cont,cat = cont_cat_split(df, 1, dep_var=dep_var)\n",
        "to = TabularPandas(df, procs, cat, cont, y_names=dep_var, splits=splits)\n",
        "to.show(3)\n",
        "save_pickle(data_path/'to.pkl',to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Decision tree\n",
        "First define x and y, the independent and dependent variables. Then create the decision tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "trn_xs,trn_y = to.train.xs,to.train.y\n",
        "valid_xs,valid_y = to.valid.xs,to.valid.y\n",
        "m = DecisionTreeRegressor(max_leaf_nodes=4)\n",
        "m.fit(xs, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This function visualizes the decision tree for the training x data that's been passed to the tabularpandas. The first node is before anything has been done. The value is the mean of the variable we're trying to predict, yield, and the sample is the length of the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import graphviz\n",
        "\n",
        "def draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n",
        "    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n",
        "                      special_characters=True, rotate=False, precision=precision, **kwargs)\n",
        "    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))\n",
        "draw_tree(m, trn_xs, size=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can confirm by checking summary statistics on the training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "df.iloc[train_idx].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next two nodes come from bisecting the dataset by values for fruitset above and below 0.5.\n",
        "\n",
        "Alternative visualization using dtreeviz, showing the distribution of data along with the bisecting lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "dtreeviz.model(m, X_train=xs, y_train=y, feature_names=df.columns, target_name=dep_var).view()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These previews were limited to just 4 nodes but now we will remove it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "m = DecisionTreeRegressor(max_leaf_nodes=4)\n",
        "m.fit(xs, y);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The Kaggle competition that this data was taken from will evaluate models based on mean absolute error\n",
        "\n",
        "{{< katex >}}\n",
        "`\\(( MAE = \\frac{1}{n}\\sum_{i=1}^n|x_1 - y_1| \\))`{=markdown}\n",
        "\n",
        "where each `\\\\( x_i \\\\)`{=markdown} represents the predicted target, `\\\\( y_i \\\\)`{=markdown}  represents the ground truth, and `\\\\( n \\\\)`{=markdown} is the number of rows in the test set."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}