### The waterfall in the woods
Based on how decision trees work, it's simple to visualize the importance of each factor in regards to a prediction using the `treeinterpreter` and `waterfallcharts` libraries. The former will calculate importance for every factor, similar to sklearn above, but for a single row rather than the entire model.
```{python}
from treeinterpreter import treeinterpreter
from waterfall_chart import plot as waterfall

prediction,bias,contributions = treeinterpreter.predict(m, valid_xs)
waterfall(valid_xs.columns, contributions[0], threshold=0.08, 
          rotation_value=45,formatting='{:,.3f}');
```
