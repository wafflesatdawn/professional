### The waterfall in the woods
Based on how decision trees work, it's simple to visualize the importance of each factor in regards to a prediction using the `treeinterpreter` and `waterfallcharts` libraries. The former will calculate importance for every factor, similar to sklearn above, but for a single row rather than the entire model.
```{python}
from treeinterpreter import treeinterpreter
from waterfall_chart import plot as waterfall

prediction,bias,contributions = treeinterpreter.predict(m, valid_xs)
waterfall(valid_xs.columns, contributions[0], threshold=0.08, 
          rotation_value=45,formatting='{:,.3f}');
```


## Deep learning version
Now let's see what kind of MAE a neural network would produce. We need to take the same steps for data prep as with the tabular models
```{python}
df_nn = pd.read_csv(data_path/'train.csv', low_memory=False)
df_nn.clonesize = df_nn.clonesize.astype('category')
df_nn.honeybee = df_nn.honeybee.astype('category')
df_nn.bumbles = df_nn.bumbles.astype('category')
df_nn.andrena = df_nn.andrena.astype('category')
df_nn.osmia = df_nn.osmia.astype('category')
cont_nn,cat_nn = cont_cat_split(df_nn, dep_var=dep_var)

procs_nn = [FillMissing, Normalize]
to_nn = TabularPandas(df_nn, procs_nn, cat_nn, cont_nn,
                      splits=splits, y_names=dep_var)
dls = to_nn.dataloaders(1024)
```
Decision trees and random forests don't care about normalized data but neural networks definitely do. Additionally, we set the batch size pretty high to 1024 because memory consumption won't be very high with tabular data.

```{python}
y = to_nn.train.y
y.min(),y.max()
```
We also set the y range close to the minimum and maximum observed values for y to initialize the `tabular_learner` with and find the best learning rate
```{python}
y = to_nn.train.y
y.min(),y.max()
learn = tabular_learner(dls, y_range=(1900, 9000), layers=[500,250],
                        n_out=1)
learn.lr_find()
```
